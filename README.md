# big-data-labs
Here's a brief overview of the labs included:

**Lab 1: Word Count in Shell**
- Focus: Basic text processing and distributed computing concepts.
- Tools: Shell Scripting, Hadoop.
- Objective: Implement the classic "word count" example on a text dataset using shell commands and Hadoop's MapReduce paradigm.

**Lab 2: List Operations in Spark**
- Focus: Data manipulation and aggregation using Spark.
- Tools: Python, Spark.
- Objective: Perform various operations on lists in Spark, such as calculating sum, min, max, retrieving the first element, and finding the top N elements. Explore different approaches like `treeAggregate`, `fold`, and others.

**Lab 3: Removing Duplicates and Analyzing Flight Data**
- Focus: Data cleaning, transformation, and analysis with Pig.
- Tools: Pig Latin, Hadoop, Python.
- Objective: Analyze a flight dataset (DataExpo2009.zip) to determine the month with the least departure and arrival delays. Use Pig to load, filter, group, and aggregate data, and visualize the results in Python.

**Lab 4: Building a Mail Classifier Pipeline**
- Focus: Machine learning pipeline creation and text classification.
- Tools: Python, Spark MLlib.
- Objective: Develop a machine learning pipeline to classify emails into different topics. Utilize Spark MLlib for tasks like tokenization, stop word removal, hashing, and training a Random Forest classifier.
